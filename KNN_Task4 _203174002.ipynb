{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"KNN_Task4 _203174002.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"cells":[{"cell_type":"markdown","metadata":{"id":"cPP7BfqFSgyH"},"source":["# K-Nearest Neighbors Algorithm\n"]},{"cell_type":"markdown","metadata":{"id":"Zd0p7ZUpSgyL"},"source":["![example 1.png](data:image/png;base64,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)In this Jupyter Notebook we will focus on $KNN-Algorithm$. KNN is a data classification algorithm that attempts to determine what group a data point is in by looking at the data points around it.\n","\n","An algorithm, looking at one point on a grid, trying to determine if a point is in group A or B, looks at the states of the points that are near it. The range is arbitrarily determined, but the point is to take a sample of the data. If the majority of the points are in group A, then it is likely that the data point in question will be A rather than B, and vice versa.\n","<br>\n","\n","<img src=\"knn/example 1.png\"  height=\"30%\" width=\"30%\">\n"]},{"cell_type":"markdown","metadata":{"id":"TyGHDf4NSgyM"},"source":["# Imports"]},{"cell_type":"code","metadata":{"id":"iIEvA0xjSgyN","executionInfo":{"status":"ok","timestamp":1635250818719,"user_tz":-330,"elapsed":418,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}}},"source":["import numpy as np\n","from tqdm import tqdm_notebook"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rc8ruF56SgyO"},"source":["# How it works?\n","\n","We have some labeled data set $X-train$, and a new set $X$ that we want to classify based on previous classifications\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rGbvEXbvSgyO"},"source":["## Seps"]},{"cell_type":"markdown","metadata":{"id":"B-nf9G4ZSgyP"},"source":["### 1. Calculate distance to all neighbours\n","### 2. Sort neightbours (based on closest distance)\n","### 3. Count possibilities of each class for k nearest neighbours \n","### 4. The class with highest possibilty is Your prediction"]},{"cell_type":"markdown","metadata":{"id":"LuWwKdFrSgyP"},"source":["# 1. Calculate distance to all neighbours\n","\n","Depending on the problem You should use different type of count distance method.\n","<br>\n","For example we can use Euclidean distance. Euclidean distance is the \"ordinary\" straight-line distance between two points in D-Dimensional space\n","\n","#### Definiton\n","$d(p, q) = d(q, p) = \\sqrt{(q_1 - p_1)^2 + (q_2 - p_2)^2 + \\dots + (q_D - p_D)^2} = \\sum_{d=1}^{D} (p_d - q_d)^2$\n","\n","#### Example\n","Distance in $R^2$\n","<img src=\"knn/euklidean_example.png\"  height=\"30%\" width=\"30%\">\n","\n","\n","$p = (4,6)$\n","<br>\n","$q = (1,2)$\n","<br>\n","$d(p, q) = \\sqrt{(1-4)^2 + (2-6)^2} =\\sqrt{9 + 16} = \\sqrt{25} = 5 $\n","\n"]},{"cell_type":"markdown","metadata":{"id":"vlvNZqiJSgyQ"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"EvmQi6nsSgyR","executionInfo":{"status":"ok","timestamp":1635250723579,"user_tz":-330,"elapsed":1651,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}}},"source":["def get_euclidean_distance(A_matrix, B_matrix):\n","    \n","    C = [ [ 0 for i in range(np.size(B_matrix, 0)) ] for j in range(np.size(A_matrix, 0)) ]\n","    \n","    for i in range (0, np.size(A_matrix, 0)):\n","        row1 = A_matrix[i,:]\n","        for j in range (0, np.size(B_matrix, 0)):\n","            row2 = B_matrix[j,:]\n","    \n","            C[i][j] = np.sum(np.square(row1 - row2))\n","    \n","    ## Use the distance formula for the matrices using numpy functions\n","    ## C is the sum of the squares of the distances\n","\n","    return np.sqrt(C)\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GABzTa_0SgyS"},"source":["## Example Usage"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W6b8yBSoSgyS","executionInfo":{"status":"ok","timestamp":1635250824471,"user_tz":-330,"elapsed":411,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"966f10e6-5429-4f7e-e70f-50df76e1b2ca"},"source":["X = np.array([[1,2,3] , [-4,5,-6]])\n","\n","X_train = np.array([[0,0,0], [1,2,3], [4,5,6], [-4, 4, -6]])\n","\n","print(\"X: {} Exaples in {} Dimensional space\".format(*X.shape))\n","print(\"X_train: {} Exaples in {} Dimensional space\".format(*X_train.shape))\n","\n","\n","print()\n","\n","print(\"X:\")\n","print(X)\n","\n","print()\n","\n","print(\"X_train\")\n","print(X_train)\n"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["X: 2 Exaples in 3 Dimensional space\n","X_train: 4 Exaples in 3 Dimensional space\n","\n","X:\n","[[ 1  2  3]\n"," [-4  5 -6]]\n","\n","X_train\n","[[ 0  0  0]\n"," [ 1  2  3]\n"," [ 4  5  6]\n"," [-4  4 -6]]\n"]}]},{"cell_type":"code","metadata":{"id":"kB8IZcDpSgyT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635250828586,"user_tz":-330,"elapsed":423,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"e48c7a0f-c233-44a7-baa1-66354fc59437"},"source":["## Initialize the distance matrix using the get_euclidean_matrix\n","\n","C = get_euclidean_distance(X, X_train)\n","\n","## Euclidean distance b/w row i of X and row j of X_train is available as C[i][j]\n","\n","\n","## Print Distance between first example from X and first form X_train\n","print(f\"Distance between first example from X and first form X_train {C[0,0]}\")"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Distance between first example from X and first form X_train 3.7416573867739413\n"]}]},{"cell_type":"markdown","metadata":{"id":"vbaJfBihSgyT"},"source":["# 2. Sort neightbours\n","\n","In order to find best fitting class for our observations we need to find to which classes belong observation neightbours and then to sort classes based on the closest distance\n"]},{"cell_type":"markdown","metadata":{"id":"b1VLHUj2SgyU"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"na0G1o_ASgyU"},"source":["def get_sorted_train_labels(distance_matrix, y):\n","    \"\"\"\n","    Function sorts y labels, based on probabilities from distances matrix\n","    Args:\n","        distance_matrix (numpy.ndarray): Distance Matrix, between points from X and X_train, size: N1:N2\n","        y (numpy.ndarray): vector of classes of X points, size: N1\n","\n","    Returns:\n","        numpy.ndarray: labels matrix sorted according to distances to nearest neightours, size N1:N2 \n","\n","    \"\"\"\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U0I8eltDSgyV"},"source":["# 3. Count possibilities of each class for k nearest neighbours \n","\n","In order to find best class for our observation $x$ we need to calculate the probability of belonging to each class. In our case it is quite easy. We need just to count how many from k-nearest-neighbours of observation $x$ belong to each class and then devide it by k \n","<br><br>\n","$p(y=class \\space| x)  = \\frac{\\sum_{1}^{k}(1 \\space if \\space N_i = class, \\space else \\space 0) }{k}$ Where $N_i$ is $i$ nearest neightbour\n","\n"]},{"cell_type":"markdown","metadata":{"id":"j0ZtOC38SgyV"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"y2aaG2GdSgyV"},"source":["def get_p_y_x_using_knn(y, k):\n","    \"\"\"\n","    The function determines the probability distribution p (y | x)\n","    for each of the labels for objects from the X\n","    using the KNN classification learned on the X_train\n","\n","    Args:\n","        y (numpy.ndarray): Sorted matrix of N2 nearest neighbours labels, size N1:N2\n","        k (int): number of nearest neighbours for KNN algorithm\n","\n","    Returns: numpy.ndarray: Matrix of probabilities for N1 points (from set X) of belonging to each class,\n","    size N1:C (where C is number of classes)\n","    \"\"\"\n","\n","    ## Write your code here\n","\n","    return probabilities_matrix\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ThEbAnXISgyW"},"source":["# 4. The class with highest possibilty is Your prediction"]},{"cell_type":"markdown","metadata":{"id":"_i7NTtN4SgyW"},"source":["At the end we combine all previous steps to get prediction"]},{"cell_type":"markdown","metadata":{"id":"OzK6rY8mSgyW"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"DaYqr_i6SgyW","executionInfo":{"status":"ok","timestamp":1635250858682,"user_tz":-330,"elapsed":471,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}}},"source":["def predict(X, X_train, y_train, k, distance_function):\n","    \"\"\"\n","    Function returns predictions for new set X based on labels of points from X_train\n","    Args:\n","        X (numpy.ndarray): set of observations (points) that we want to label\n","        X_train (numpy.ndarray): set of lalabeld bservations (points)\n","        y_train (numpy.ndarray): labels for X_train\n","        k (int): number of nearest neighbours for KNN algorithm\n","\n","    Returns:\n","        (numpy.ndarray): label predictions for points from set X\n","    \"\"\"\n","    ## Write your code here\n","\n","    return prediction"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i9kzyASWSgyX"},"source":["# Accuracy"]},{"cell_type":"markdown","metadata":{"id":"v8bNPTPZSgyX"},"source":["To find how good our knn model works we should count accuracy"]},{"cell_type":"markdown","metadata":{"id":"dgFCnJ14SgyX"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"2ySpyThlSgyX"},"source":["def count_accuracy(prediction, y_true):\n","    \"\"\"\n","    Returns:\n","        float: Predictions accuracy\n","\n","    \"\"\"\n","    N1 = prediction.shape[0]\n","    \n","    ## Use np.sum to count the number of elements where predicted value == actual value and assign the count to the variable accuracy\n","\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b5g7YFY2SgyX"},"source":["## Example usage"]},{"cell_type":"code","metadata":{"id":"uLqCqmJNSgyY","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"error","timestamp":1635250842268,"user_tz":-330,"elapsed":449,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"dcf624ee-b959-4577-b370-464112163929"},"source":["y_true = np.array([[0, 2]])\n","\n","predicton = predict(X, X_train, y_train, 3, get_euclidean_distance)\n","\n","\n","print(\"True classes:{}, accuracy {}%\".format(y_true, count_accuracy(predicton, y_true)  * 100))"],"execution_count":8,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e0b02676c018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredicton\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_euclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"--WUpIcxSgyY"},"source":["# Find best k"]},{"cell_type":"markdown","metadata":{"id":"itkcD0DlSgyY"},"source":["Best k parameter is that one for which we have highest accuracy"]},{"cell_type":"markdown","metadata":{"id":"7GYEUBnnSgyY"},"source":["## Code"]},{"cell_type":"code","metadata":{"id":"Q6OhNBOoSgyY","executionInfo":{"status":"ok","timestamp":1635250862606,"user_tz":-330,"elapsed":413,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}}},"source":["def select_knn_model(X_validation, y_validation, X_train, y_train, k_values, distance_function):\n","    \"\"\"\n","    Function returns k parameter that best fit Xval points\n","    Args:\n","        Xval (numpy.ndarray): set of Validation Data, size N1:D\n","        Xtrain (numpy.ndarray): set of Training Data, size N2:D\n","        yval (numpy.ndarray): set of labels for Validation data, size N1:1\n","        ytrain (numpy.ndarray): set of labels for Training Data, size N2:1\n","        k_values (list): list of int values of k parameter that should be checked\n","\n","    Returns:\n","        int: k paprameter that best fit validation set\n","    \"\"\"\n","\n","    accuracies = []\n","\n","    for k in tqdm_notebook(k_values):\n","        prediction = predict(X_validation, X_train, y_train, k, distance_function)\n","\n","        accuracy = count_accuracy(prediction, y_validation)\n","        accuracies.append(accuracy)\n","\n","    best_k = k_values[accuracies.index(max(accuracies))]\n","\n","    return best_k, accuracies\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nGtIjD0WSgyY"},"source":["# Real World Example - Iris Dataset"]},{"cell_type":"markdown","metadata":{"id":"-o6MHMtKSgyZ"},"source":["\n","<img src=\"knn/iris_example1.jpeg\"  height=\"60%\" width=\"60%\">\n","\n","\n","This is perhaps the best known database to be found in the pattern recognition literature. The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. \n","\n","Each example contains 4 attributes\n","1. sepal length in cm \n","2. sepal width in cm \n","3. petal length in cm \n","4. petal width in cm \n","\n","Predicted attribute: class of iris plant. \n","\n","<img src=\"knn/iris_example2.png\"  height=\"70%\" width=\"70%\">\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SY8oOngQSgyZ","executionInfo":{"status":"ok","timestamp":1635250867474,"user_tz":-330,"elapsed":414,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"270c2090-4cc4-43c8-dd20-5ed2670e0067"},"source":["from sklearn import datasets\n","import matplotlib.pyplot as plt\n","\n","iris = datasets.load_iris()\n","\n","iris_X = iris.data\n","iris_y = iris.target\n","\n","print(\"Iris: {} examples in {} dimensional space\".format(*iris_X.shape))\n","print(\"First example in dataset :\\n Speal lenght: {}cm \\n Speal width: {}cm \\n Petal length: {}cm \\n Petal width: {}cm\".format(*iris_X[0]))\n","\n","print(\"Avalible classes\", np.unique(iris_y))"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Iris: 150 examples in 4 dimensional space\n","First example in dataset :\n"," Speal lenght: 5.1cm \n"," Speal width: 3.5cm \n"," Petal length: 1.4cm \n"," Petal width: 0.2cm\n","Avalible classes [0 1 2]\n"]}]},{"cell_type":"markdown","metadata":{"id":"-IlKSX7hSgyZ"},"source":["## Prepare Data\n","\n","In our data set we have 150 examples (50 examples of each class), we have to divide it into 3 datasets.\n","1. Training data set, 90 examples. It will be used to find  k - nearest neightbours\n","2. Validation data set, 30 examples. It will be used to find best k parameter, the one for which accuracy is highest\n","3. Test data set, 30 examples. It will be used to check how good our model performs\n","\n","Data has to be shuffled (mixed in random order), because originally it is stored 50 examples of class 0, 50 of 1 and 50 of 2.\n"]},{"cell_type":"code","metadata":{"id":"RA1Q7kCPSgyZ","executionInfo":{"status":"ok","timestamp":1635250871691,"user_tz":-330,"elapsed":418,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}}},"source":["from sklearn.utils import shuffle\n","\n","iris_X, iris_y = shuffle(iris_X, iris_y, random_state=134)\n","\n","\n","test_size = 30\n","validation_size = 30\n","training_size = 90\n","\n","## Initialize X_test\n","## Initialize X_validation \n","## Initialize X_train \n","\n","## Initialize y_test\n","## Initialize y_validation\n","## Initialize y_train"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9xJVLzrSgyZ"},"source":["## Find best k parameter"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"hbvZBVNBSgya","executionInfo":{"status":"error","timestamp":1635250875803,"user_tz":-330,"elapsed":430,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"f62b15f9-7fca-4789-bac2-2db5cbbcd8c0"},"source":["k_values = [i for i in range(3,50)]\n","\n","best_k, accuracies = select_knn_model(X_validation, y_validation, X_train, y_train, k_values, distance_function=get_euclidean_distance)\n","\n","## Plot accuracy vs k values graph"],"execution_count":13,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-f62dfe6ed899>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mk_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_knn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_euclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m## Plot accuracy vs k values graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_validation' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"BjQBDWJMSgya"},"source":["## Count accuracy for training set"]},{"cell_type":"code","metadata":{"id":"_f-J5sSESgya","colab":{"base_uri":"https://localhost:8080/","height":201},"executionInfo":{"status":"error","timestamp":1635250882340,"user_tz":-330,"elapsed":434,"user":{"displayName":"Desu Venkata Manikanta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"10818416874497828882"}},"outputId":"d0dfb811-a65e-472c-bdc7-fad839ccc488"},"source":["prediction = predict(X_test, X_train, y_train, best_k, get_euclidean_distance)\n","\n","## Calculate Best accuracy using the best k value\n"],"execution_count":14,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-304d88a7873b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_euclidean_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Calculate Best accuracy using the best k value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"72O5eXbCSgyc"},"source":["# Sources\n","\n","https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm - first visualisation image\n","\n","https://en.wikipedia.org/wiki/Euclidean_distance - euclidean distance visualisation\n","\n","https://rajritvikblog.wordpress.com/2017/06/29/iris-dataset-analysis-python/ - first iris image\n","\n","https://rpubs.com/wjholst/322258 - second iris image\n","\n"]}]}